{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from eval import evaluate_with_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the results folder:\n",
      "results_gpt-3.5-turbo-0125_0.0.csv\n",
      "results_togethercomputer_CodeLlama-34b-Instruct_0.0.csv\n",
      "results_meta-llama_Llama-3-70b-chat-hf_0.0.csv\n",
      "results_mistralai_Mixtral-8x7B-Instruct-v0.1_0.0.csv\n"
     ]
    }
   ],
   "source": [
    "# List all files in the results folder\n",
    "results_folder = './results'\n",
    "files_in_results = os.listdir(results_folder)\n",
    "print(\"Files in the results folder:\")\n",
    "for file in files_in_results:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import each CSV file into a pandas DataFrame and store them in a dictionary\n",
    "dataframes = {}\n",
    "for file in files_in_results:\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(results_folder, file)\n",
    "        dataframes[file.replace('.csv', '').replace('results_', '')] = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>result</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>model_name</th>\n",
       "      <th>correct</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "      <td>SELECT COUNT(*) FROM head WHERE age &gt; 56</td>\n",
       "      <td>CREATE TABLE head (age INTEGER)</td>\n",
       "      <td>SELECT COUNT(*) FROM head WHERE age &gt; 56</td>\n",
       "      <td>True</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>_col_0\\n     3</td>\n",
       "      <td>_col_0\\n     3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "      <td>SELECT name, born_state, age FROM head ORDER B...</td>\n",
       "      <td>CREATE TABLE head (name VARCHAR, born_state VA...</td>\n",
       "      <td>SELECT name, born_state, age FROM head ORDER B...</td>\n",
       "      <td>True</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>name born_state age\\nEmil    Florida  35\\nJane...</td>\n",
       "      <td>name born_state age\\nEmil    Florida  35\\nJane...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "      <td>SELECT creation, name, budget_in_billions FROM...</td>\n",
       "      <td>CREATE TABLE department (creation VARCHAR, nam...</td>\n",
       "      <td>SELECT creation, name, budget_in_billions FROM...</td>\n",
       "      <td>True</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>creation name budget_in_billions\\n    2005 Fin...</td>\n",
       "      <td>creation name budget_in_billions\\n    2005 Fin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "      <td>SELECT MAX(budget_in_billions), MIN(budget_in_...</td>\n",
       "      <td>CREATE TABLE department (budget_in_billions IN...</td>\n",
       "      <td>SELECT MAX(budget_in_billions) AS maximum_budg...</td>\n",
       "      <td>True</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>_col_0 _col_1\\n     5      1</td>\n",
       "      <td>maximum_budget minimum_budget\\n             5 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "      <td>SELECT AVG(num_employees) FROM department WHER...</td>\n",
       "      <td>CREATE TABLE department (num_employees INTEGER...</td>\n",
       "      <td>SELECT AVG(num_employees) FROM department WHER...</td>\n",
       "      <td>True</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>_col_0\\n63.333</td>\n",
       "      <td>_col_0\\n63.333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How many heads of the departments are older th...   \n",
       "1  List the name, born state and age of the heads...   \n",
       "2  List the creation year, name and budget of eac...   \n",
       "3  What are the maximum and minimum budget of the...   \n",
       "4  What is the average number of employees of the...   \n",
       "\n",
       "                                              answer  \\\n",
       "0           SELECT COUNT(*) FROM head WHERE age > 56   \n",
       "1  SELECT name, born_state, age FROM head ORDER B...   \n",
       "2  SELECT creation, name, budget_in_billions FROM...   \n",
       "3  SELECT MAX(budget_in_billions), MIN(budget_in_...   \n",
       "4  SELECT AVG(num_employees) FROM department WHER...   \n",
       "\n",
       "                                             context  \\\n",
       "0                    CREATE TABLE head (age INTEGER)   \n",
       "1  CREATE TABLE head (name VARCHAR, born_state VA...   \n",
       "2  CREATE TABLE department (creation VARCHAR, nam...   \n",
       "3  CREATE TABLE department (budget_in_billions IN...   \n",
       "4  CREATE TABLE department (num_employees INTEGER...   \n",
       "\n",
       "                                              result  is_correct  \\\n",
       "0           SELECT COUNT(*) FROM head WHERE age > 56        True   \n",
       "1  SELECT name, born_state, age FROM head ORDER B...        True   \n",
       "2  SELECT creation, name, budget_in_billions FROM...        True   \n",
       "3  SELECT MAX(budget_in_billions) AS maximum_budg...        True   \n",
       "4  SELECT AVG(num_employees) FROM department WHER...        True   \n",
       "\n",
       "           model_name                                            correct  \\\n",
       "0  gpt-3.5-turbo-0125                                     _col_0\\n     3   \n",
       "1  gpt-3.5-turbo-0125  name born_state age\\nEmil    Florida  35\\nJane...   \n",
       "2  gpt-3.5-turbo-0125  creation name budget_in_billions\\n    2005 Fin...   \n",
       "3  gpt-3.5-turbo-0125                       _col_0 _col_1\\n     5      1   \n",
       "4  gpt-3.5-turbo-0125                                     _col_0\\n63.333   \n",
       "\n",
       "                                          prediction error  temperature  \n",
       "0                                     _col_0\\n     3   NaN          0.0  \n",
       "1  name born_state age\\nEmil    Florida  35\\nJane...   NaN          0.0  \n",
       "2  creation name budget_in_billions\\n    2005 Fin...   NaN          0.0  \n",
       "3  maximum_budget minimum_budget\\n             5 ...   NaN          0.0  \n",
       "4                                     _col_0\\n63.333   NaN          0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['gpt-3.5-turbo-0125_0.0'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the 'is_correct' column for each DataFrame and store the results in a dictionary\n",
    "results = {}\n",
    "for file_name, df in dataframes.items():\n",
    "    results[file_name] = df['is_correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataframes['gpt-3.5-turbo-0125_0.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating with LLM:   0%|          | 0/328 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A: 0.0, B: 0.0, C: 1.0:   0%|          | 1/328 [00:04<25:25,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A: 0.0, B: 0.0, C: 1.0:   1%|          | 2/328 [00:08<22:51,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A: 0.0, B: 0.0, C: 1.0:   1%|          | 3/328 [00:13<25:29,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A: 0.0, B: 0.0, C: 1.0:   1%|          | 4/328 [00:17<23:18,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A: 0.0, B: 0.0, C: 1.0:   2%|▏         | 5/328 [00:21<22:53,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A: 0.0, B: 0.0, C: 1.0:   2%|▏         | 6/328 [00:25<22:15,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A: 0.0, B: 0.0, C: 1.0:   2%|▏         | 7/328 [00:29<21:22,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A: 0.0, B: 0.0, C: 1.0:   2%|▏         | 8/328 [00:33<20:47,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A: 0.0, B: 0.0, C: 1.0:   3%|▎         | 9/328 [00:36<20:04,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A: 0.0, B: 0.0, C: 1.0:   3%|▎         | 10/328 [00:41<21:59,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A: 0.0, B: 0.0, C: 1.0:   3%|▎         | 10/328 [00:42<22:36,  4.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(a\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39ma\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating with LLM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Execute the evaluation with LLM\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     evaluation_result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Store the result in the new column\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     a\u001b[38;5;241m.\u001b[39mat[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllm_evaluation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m evaluation_result\n",
      "File \u001b[0;32m~/code/sql_cot/eval.py:54\u001b[0m, in \u001b[0;36mevaluate_with_llm\u001b[0;34m(answer, prediction_query, context, question)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in LLM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m votes\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Add a new column to store the evaluation results\n",
    "a['llm_evaluation'] = None\n",
    "\n",
    "# Options counter\n",
    "counter = {'A': 0, 'B': 0, 'C': 0}\n",
    "\n",
    "# Iterate over each row in DataFrame 'a' using tqdm for progress bar\n",
    "pbar = tqdm(a.iterrows(), total=a.shape[0], desc=\"Evaluating with LLM\")\n",
    "for index, row in pbar:\n",
    "    # Execute the evaluation with LLM\n",
    "    evaluation_result = evaluate_with_llm(answer=row['answer'], prediction_query=row['prediction'], context=row['question'], question=row['question'])\n",
    "    \n",
    "    # Store the result in the new column\n",
    "    a.at[index, 'llm_evaluation'] = evaluation_result\n",
    "\n",
    "    print(evaluation_result)\n",
    "    for sel in evaluation_result:\n",
    "        counter[sel] += 1\n",
    "    pbar.set_description(f\"A: {counter['A']/((index+1)*3)}, B: {counter['B']/((index+1)*3)}, C: {counter['C']/((index+1)*3)}\")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "a.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql-cot-CPMFhG_L-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
